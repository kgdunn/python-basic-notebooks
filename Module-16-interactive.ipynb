{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Review-so-far\" data-toc-modified-id=\"Review-so-far-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Review so far</a></span></li><li><span><a href=\"#Data-set-import-and-basic-checks\" data-toc-modified-id=\"Data-set-import-and-basic-checks-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data set import and basic checks</a></span></li><li><span><a href=\"#Reading-only-certain-rows\" data-toc-modified-id=\"Reading-only-certain-rows-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Reading only certain rows</a></span></li><li><span><a href=\"#Import-specific-columns-only\" data-toc-modified-id=\"Import-specific-columns-only-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Import specific columns only</a></span></li><li><span><a href=\"#Dropping-columns-or-rows\" data-toc-modified-id=\"Dropping-columns-or-rows-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Dropping columns or rows</a></span></li><li><span><a href=\"#Setting-an-index\" data-toc-modified-id=\"Setting-an-index-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Setting an index</a></span></li><li><span><a href=\"#Deleting-missing-values\" data-toc-modified-id=\"Deleting-missing-values-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Deleting missing values</a></span></li><li><span><a href=\"#Using-iloc-and-loc\" data-toc-modified-id=\"Using-iloc-and-loc-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Using iloc and loc</a></span></li><li><span><a href=\"#Dropping-missing-values,-specifying-a-threshold\" data-toc-modified-id=\"Dropping-missing-values,-specifying-a-threshold-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Dropping missing values, specifying a threshold</a></span></li><li><span><a href=\"#Filtering-rows\" data-toc-modified-id=\"Filtering-rows-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Filtering rows</a></span></li><li><span><a href=\"#Filling-in-missing-values\" data-toc-modified-id=\"Filling-in-missing-values-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Filling in missing values</a></span></li><li><span><a href=\"#isin-funcion\" data-toc-modified-id=\"isin-funcion-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>isin funcion</a></span></li><li><span><a href=\"#Multilevel-groupby\" data-toc-modified-id=\"Multilevel-groupby-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Multilevel groupby</a></span></li><li><span><a href=\"#Multiple-groupby-summaries\" data-toc-modified-id=\"Multiple-groupby-summaries-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Multiple groupby summaries</a></span></li><li><span><a href=\"#Mixed-groupby\" data-toc-modified-id=\"Mixed-groupby-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Mixed groupby</a></span></li><li><span><a href=\"#Add-a-new-column,-not-at-the-end\" data-toc-modified-id=\"Add-a-new-column,-not-at-the-end-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Add a new column, not at the end</a></span></li><li><span><a href=\"#REplace-values-in-a-column\" data-toc-modified-id=\"REplace-values-in-a-column-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>REplace values in a column</a></span></li><li><span><a href=\"#Rounding\" data-toc-modified-id=\"Rounding-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>Rounding</a></span></li><li><span><a href=\"#Display-options\" data-toc-modified-id=\"Display-options-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>Display options</a></span></li><li><span><a href=\"#Styling\" data-toc-modified-id=\"Styling-20\"><span class=\"toc-item-num\">20&nbsp;&nbsp;</span>Styling</a></span></li><li><span><a href=\"#Five-main-goals-with-data-science\" data-toc-modified-id=\"Five-main-goals-with-data-science-21\"><span class=\"toc-item-num\">21&nbsp;&nbsp;</span>Five main goals with data science</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examples-of-using-this-categorization\" data-toc-modified-id=\"Examples-of-using-this-categorization-21.1\"><span class=\"toc-item-num\">21.1&nbsp;&nbsp;</span>Examples of using this categorization</a></span></li><li><span><a href=\"#Try-it-yourself\" data-toc-modified-id=\"Try-it-yourself-21.2\"><span class=\"toc-item-num\">21.2&nbsp;&nbsp;</span>Try it yourself</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All content here is under a Creative Commons Attribution [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/) and all source code is released under a [BSD-2 clause license](https://en.wikipedia.org/wiki/BSD_licenses).\n",
    ">\n",
    ">Please reuse, remix, revise, and [reshare this content](https://github.com/kgdunn/python-basic-notebooks) in any way, keeping this notice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course overview\n",
    "\n",
    "This is the sixth, and final, module of several (11, 12, 13, 14, 15 and 16), which refocuses the course material in the [first 10  modules](https://github.com/kgdunn/python-basic-notebooks) in a slightly different way. It places more emphasis on\n",
    "\n",
    "* dealing with data: importing, merging, filtering;\n",
    "* calculations from the data;\n",
    "* visualization of it.\n",
    "\n",
    "In short: ***how to extract value from your data***.\n",
    "\n",
    "## Review so far\n",
    "\n",
    "In [module 11](https://yint.org/pybasic11) we learned about\n",
    "* creating variables, and showing their `type` \n",
    "* performing basic calculations, and the `math` library\n",
    "* lists, as one of the most fundamental Python objects\n",
    "\n",
    "In the [module 12](https://yint.org/pybasic12) we took this a step further:\n",
    "* and introduced the Pandas library, for `Series` and `DataFrame` objects\n",
    "* learned how to import and write Excel files\n",
    "* do basic operations on DataFrames, and \n",
    "* learned about another fundamental Python type, the `dict`ionary.\n",
    "\n",
    "[Module 13](https://yint.org/pybasic13) we introduced:\n",
    "* a general workflow for data processing\n",
    "* and haw to visualize data with Pandas:\n",
    "\n",
    "    * box plot, \n",
    "    * time series (sequence) plot, and\n",
    "    * scatter plots [including showing how you can visualize 5 dimensions!]\n",
    "\n",
    "[Module 14](https://yint.org/pybasic14) we saw how to create:\n",
    "* for loops, for when we need to do things over and over,\n",
    "* by we also saw the `groupby` function, which does actions repeatedly on sub-groups of your data.\n",
    "* We also introduced the correlation matrix.\n",
    "\n",
    "Then in [module 15](https://yint.org/pybasic15) we saw:\n",
    "* that we could visualize the correlation matrix (2D histogram), to find candidates for regression,\n",
    "* using the `LinearRegression` tool from a new library, `scikit-learn`.\n",
    "* We also used another new library, `seaborn`, to visualize the regression models.\n",
    "\n",
    "\n",
    "# Module 16 Overview\n",
    "\n",
    "In this module we will cover\n",
    "\n",
    "* A bunch of loose ideas of things you regularly need in your day-to-day work. Most of these come from this list, with some modifications: https://towardsdatascience.com/30-examples-to-master-pandas-f8a2da751fa4\n",
    "* We close with a generic framework for things you can do to extract value from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set import and basic checks\n",
    "\n",
    "We will use a data set that ... <complete>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\")\n",
    "display(df.head(10))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the correlation matrix is essential to help understanding relationships. Use the code and the plot below to help answer:\n",
    "\n",
    "* Countries which consume garlic more than average, also seem to consume a higher amount of ...\n",
    "* Which variables are negatively correlated with \"Real coffee\" consumption?\n",
    "* Countries with higher consumption of \"Crisp bread\" also show high consumption of which other products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(15, 15)})\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(df.corr(), cmap=cmap,  square=True, linewidths=0.2, cbar_kws={\"shrink\": 0.5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading only certain rows\n",
    "\n",
    "Imagine you had a large data set, and only needed certain rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\", nrows=5)\n",
    "display(df_subset)\n",
    "\n",
    "df_partial = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\", skiprows=[2, 3, 4])\n",
    "display(df_partial)\n",
    "\n",
    "# Requires an extra `engine` input\n",
    "df_bottom = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\", skipfooter=12,engine='python')\n",
    "display(df_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping every 3rd row:\n",
    "df_partial = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\", \n",
    "                         skiprows=[i for i in range(40) if i%3 ==1])\n",
    "\n",
    "# This is call a \"list comprehension\", super powerful. Read about it on your own time.\n",
    "# https://realpython.com/list-comprehension-python/#using-list-comprehensions\n",
    "print([i for i in range(40) if i%3 ==1])\n",
    "display(df_partial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import specific columns only\n",
    "\n",
    "If you know the names of the columns you need, you can use the `usecols` input (works for Excel and CSV file import)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\", \n",
    "                        usecols=[\"Country\", \"Sweetener\", \"Biscuits\", \"Powder soup\", \"Tin soup\"])\n",
    "display(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns or rows\n",
    "\n",
    "Conversely, you can read in the whole data set, and drop away the columns or rows you do not need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\")\n",
    "\n",
    "df.drop([\"Sweetener\", \"Biscuits\", \"Powder soup\", \"Tin soup\"], axis=1, inplace=True)\n",
    "display(df)\n",
    "df.shape\n",
    "\n",
    "# Also drop some rows: drop away every 3rd row.\n",
    "# Replace the \"...\" with some code\n",
    "df_subset = df.drop(... , axis=0)  # you can also leave away 'axis=0' (that's the default)\n",
    "display(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting an index\n",
    "\n",
    "You can always set a column to be your dataframe index, using the `set_index` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\")\n",
    "df = df.set_index('Country')\n",
    "display(df)\n",
    "\n",
    "# Or, in a single line:\n",
    "df = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\").set_index('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting missing values\n",
    "\n",
    "Pandas generally handles missing values well: for example, with ``df.mean()`` will work even there are missing values. But some mathematical tools cannot have missing values, such as when performing a linear regression. So deleting missing first is one option:\n",
    "\n",
    "* How many missing values per column? Or per row?\n",
    "* Delete columns with missing values.\n",
    "* Deleting rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have missing values:\n",
    "df = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\").set_index('Country')\n",
    "display(df.isna().sum())\n",
    "\n",
    "# Which rows have missing values:\n",
    "df.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the \"Sweetener\", \"Biscuits\", and \"Yoghurt\" columns are not present after running this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the rows for \"Sweden\", \"Finland\", and \"Spain\" are not present after this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping missing values in all rows, but only for a subset of the columns is possible. For example, drop only rows in the columns for \"Sweetener\" and \"Yoghurt\" (ignore the column for \"Biscuits\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.dropna(subset=[\"Sweetener\", \"Yoghurt\"], axis=0))\n",
    "\n",
    "# Note: you can also flip this around. Specify a subset of row\n",
    "#       names in `subset` and delete from all columns, using `axis=1`.\n",
    "df.dropna(subset=[\"Sweden\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using iloc and loc\n",
    "\n",
    "We learned about `.iloc` in the [prior module](https://yint.org/pybasic15). Let's look at these two again:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\").set_index('Country')\n",
    "\n",
    "# \"Instant coffee\" is column 1: make all these values missing\n",
    "df.iloc[:, 1] = np.nan\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what if don't know, or care, which column it is? If we know \n",
    "# the column name, then use \".loc\"\n",
    "df.loc[:, \"Tea\"] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you can use a list of column names:\n",
    "df.loc[:, [\"Potatoes\",\"Frozen fish\"]] = 98.76\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or a mixture of column and row names:\n",
    "df.loc[\"Holland\", \"Biscuits\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use a mixture of iloc and loc:\n",
    "df.iloc[[0, 1, 2], :].loc[:, \"Tin soup\"]\n",
    "\n",
    "# but this is less code:\n",
    "df.iloc[[0, 1, 2], :][\"Tin soup\"]\n",
    "\n",
    "# or even less\n",
    "df.iloc[[0, 1, 2]][\"Tin soup\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping missing values, specifying a threshold\n",
    "\n",
    "If you want to delete a column only if there are more than a certain number of missing values..\n",
    "\n",
    "* Read the data\n",
    "* Make a column have a high number of missing values (for demonstration purposes)\n",
    "* Remove that column, because it has a high degree of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data, and make every 3rd row a missing value for column \"Tea\"\n",
    "df = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\").set_index('Country')\n",
    "\n",
    "df.iloc[[i for i in range(16) if i%3 == 1]][\"Tea\"] = np.nan\n",
    "\n",
    "# The above code generates a warning. Why?\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to solve it? As suggested by the warning, use \".loc\" instead.\n",
    "#     df.loc[row_indexer, col_indexer] = np.nan\n",
    "\n",
    "# This is all row names:\n",
    "row_indexer = df.index\n",
    "\n",
    "# Now take every second row name:\n",
    "row_indexer = df.index[  [i for i in range(16) if i%3 ==1]  ]\n",
    "row_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[row_indexer, \"Tea\"] = np.nan\n",
    "display(df)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can now delete columns with a threshold (degree) of missing values\n",
    "# What value should you fill in?\n",
    "display(df.dropna(thresh=___, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering rows\n",
    "\n",
    "* Find which countries have `\"Olive oil\"` consumption of more than 50?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://openmv.net/file/food-consumption.csv\").set_index('Country')\n",
    "df[df[\"Olive oil\"]>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which countries have `\"Olive oil\"` more than 50, **and** `\"Garlic\"` more than 40?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"Olive oil\"]>50) & (df[\"Garlic\"]>40)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which countries have `\"Tea\"` more than 80, **or** `\"Oranges\"` more than 90?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"Tea\"]>80) | (df[\"Oranges\"]>90)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering with the `.query` function\n",
    "\n",
    "It is sometimes more natural to filter with the `.query` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"30 < Tea < 80\")\n",
    "\n",
    "# or if the column name has a space:\n",
    "df.query(\"10 < `Tin soup` < 20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have multiple queries:\n",
    "\n",
    "Find the countries which have \"Real coffee\" and \"Tea\" consumption above 70. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"(`Real coffee` > 70) and (Tea > 70)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really powerful is the ability to reference one column against another.\n",
    "\n",
    "Find all countries where more `\"Instant coffee\"` is drunk than `\"Real coffee\"`. *These are countries to avoid visiting*. What else do you notice about these countries eating habits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"`Instant coffee` > `Real coffee`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing values\n",
    "\n",
    "mode = df['Geography'].value_counts().index[0]\n",
    "df['Geography'].fillna(value=mode, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isin funcion\n",
    "\n",
    "df[df['Tenure'].isin([4,6,9,10])][:3]\n",
    "\n",
    "\n",
    "df.query('a not in b')\n",
    "\n",
    "\n",
    "Versus using the .isin function\n",
    "\n",
    "In [244]: df[~df['a'].isin(df['b'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilevel groupby\n",
    "\n",
    "df[['Geography','Gender','Exited']].groupby(['Geography','Gender']).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple groupby summaries\n",
    "df[['Geography','Gender','Exited']].groupby(['Geography','Gender']).agg(['mean','count'])\n",
    "\n",
    "df['fare'].agg(['sum', 'mean'])\n",
    "\n",
    "\n",
    "\n",
    "agg_func_math = {\n",
    "    'fare':\n",
    "    ['sum', 'mean', 'median', 'min', 'max', 'std', 'var', 'mad', 'prod']\n",
    "}\n",
    "df.groupby(['embark_town']).agg(agg_func_math).round(2)\n",
    "\n",
    "\n",
    "@ Calling a function:\n",
    "\n",
    "def sparkline_str(x):\n",
    "    bins=np.histogram(x)[0]\n",
    "    sl = ''.join(sparklines(bins))\n",
    "    return sl\n",
    "    \n",
    "and then...\n",
    "\n",
    "agg_func_largest = {\n",
    "    'fare': [percentile_90, trim_mean_10, largest, sparkline_str]\n",
    "}\n",
    "df.groupby(['class', 'embark_town']).agg(agg_func_largest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed groupby\n",
    "\n",
    "df_summary = df[['Geography','Exited','Balance']].groupby('Geography')\\\n",
    ".agg({'Exited':'sum', 'Balance':'mean'})\n",
    "df_summary.rename(columns={'Exited':'# of churned customers', 'Balance':'Average Balance of Customers'},inplace=True)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a new column, not at the end\n",
    "df_new.insert(0, 'Group', group)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REplace values in a column\n",
    "df['column'].replace({0: \"No\", 1: \"Yes\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rounding\n",
    "\n",
    "#df_new.round(1) #number of desired decimal points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sparklines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display options\n",
    "pd.set_option(\"display.precision\", 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styling\n",
    "\n",
    "df_new.style.highlight_max(axis=0, color='darkgreen')\n",
    "df.style.bar(align='mid', color=['red', 'lightgreen'])\n",
    "\n",
    "\n",
    "or\n",
    "\n",
    "(monthly_sales\n",
    " .style\n",
    " .format(format_dict)\n",
    " .hide_index()\n",
    " .bar(color='#FFA07A', vmin=100_000, subset=['sum'], align='zero')\n",
    " .bar(color='lightgreen', vmin=0, subset=['pct_of_total'], align='zero')\n",
    " .set_caption('2018 Sales Performance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://openmv.net/file/raw-material-characterization.csv\")\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five main goals with data science\n",
    "\n",
    "\n",
    "In the [prior module](https://yint.org/pybasic09) I described my approach for any data analysis project. The first step is to **define the goals**. When I take a look at various projects I have worked on, the goals always fall into one or more of these categories, or 'application domains'.\n",
    "\n",
    "1. Learning more about our system\n",
    "2. Troubleshooting a problem that is occurring\n",
    "3. Making predictions using (some) data from the system\n",
    "4. Monitoring that system in real-time, or nearly real time \n",
    "5. Optimizing the system\n",
    "\n",
    "I will describe these goals shortly. But why look at this? The reason is that certain goals can be solved with a subset of tools. The number of tools available to you is large. Knowing which one to use for which type of goal helps you along the way faster.\n",
    "\n",
    "<hr>\n",
    "Goals 1 and 2 take place off-line, using data that has been collected already.\n",
    "\n",
    "Goals 3, making predictions from the system, e.g. predicting what quality is being produced by the system; or how much longer a batch should be run before it is completed. The prediction is typically required to support other decisions, or to apply real-time control on the system. \n",
    "\n",
    "Goal 4 also can take place on-line, and is used to ensure the system is operating in a stable manner, and if not, using the data to figure what is going wrong, or about to go wrong.\n",
    "\n",
    "Goal 5 is typically off-line, and here we use the data to make longer term improvements. For example, we try to move the system to a different state of operation that is more optimal/profitable. This can also be done in real-time, where systems are continuously shifted around to track an optimum target.\n",
    "\n",
    "<hr>\n",
    "\n",
    "This is just one way to to categorize data science problems. There are of course other ways to do this: such as if you are dealing with one variable (vector) or many variables (matrices). Or which type of technique you are using: ***supervised*** or ***unsupervised***.\n",
    "\n",
    "We will encounter these terms along the way. But for now, you should be able to see any problem where you have used data as fitting into one of these five categories above. \n",
    "\n",
    "\n",
    "### Examples of using this categorization\n",
    "\n",
    "For example: your manager asks you to use data (whatever is available) to discover why we are seeing increased number of customers returning our most profitable product to the store. Your objective: Find reason(s) for increased returns of product.\n",
    "\n",
    "Which of the 5 goals above are used?: Number 2 \"Troubleshoot a problem that is occurring\" is the most direct. But along the way to achieving that goal, you will almost certainly apply number 1: \"Learn more about your system\".\n",
    "\n",
    "Following up: in the future, after you have found the reasons for returned product, you might have done number 5: \"optimizing the system\" to find settings for the machines, so that fewer low-quality products are produced. Then, in a different data science project, based on number 4: you \"monitor the system in real-time\" to prevent producing bad quality products\". This might be done by applying number 3: \"making predictions of the product quality\" in real-time, while the system is operating.\n",
    "\n",
    "\n",
    "As you can see, these 5 goals are generally very broad. Why do we mention them?\n",
    "\n",
    "You might learn, in other courses and later in your career, about different tools to implement. Then you can interchange the tools in your toolbox. For example, linear regression is one type of prediction tool to achieve goal 3, but so is a neural network. If one tool does not work so well, you can swap it for another one in your pipeline.\n",
    "\n",
    "### Try it yourself\n",
    "\n",
    "Try breaking down the existing data-based project you are currently working in. Check which one or more of the five apply.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE this. Execute this cell to load the notebook's style sheet.\n",
    "from IPython.core.display import HTML\n",
    "css_file = './images/style.css'\n",
    "#HTML(open(css_file, \"r\").read())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376.22283935546875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
